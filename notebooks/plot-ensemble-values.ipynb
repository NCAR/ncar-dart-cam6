{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Diagnostic Plots of Data in DART-CAM6 Zarr Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask\n",
    "import intake\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Connect to a Dask Distributed Cluster\n",
    "\n",
    "Run the cell below if the notebook is running on a supercomputer with a PBS Scheduler.\n",
    "If the notebook is running on a different parallel computing environment, you will need \n",
    "to replace the usage of `PBSCluster` with a similar object from `dask_jobqueue` or `dask_gateway`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_jobs = 20\n",
    "walltime = '0:20:00'\n",
    "memory='10GB' \n",
    "\n",
    "cluster = PBSCluster(cores=1, processes=1, walltime=walltime, memory=memory, queue='casper', \n",
    "                     resource_spec='select=1:ncpus=1:mem=10GB',)\n",
    "cluster.scale(jobs=num_jobs)\n",
    "\n",
    "\n",
    "from distributed import Client\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Obtain Data Using an Intake Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose Cloud Storage (AWS or NCAR Cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True,  use NCAR Cloud Storage.   \n",
    "# If False, use AWS  Cloud Storage.\n",
    "\n",
    "USE_NCAR_CLOUD_STORAGE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Intake Catalog URL and Storage Access Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_NCAR_CLOUD_STORAGE:\n",
    "    catalog_url = \"https://stratus.ucar.edu/ncar-dart-cam6/catalogs/aws-dart-cam6.json\"\n",
    "    storage_options={\"anon\": True, 'client_kwargs':{\"endpoint_url\":\"https://stratus.ucar.edu/\"}}\n",
    "                     \n",
    "else:\n",
    "    catalog_url = \"https://ncar-dart-cam6.s3-us-west-2.amazonaws.com/catalogs/aws-dart-cam6.json\"\n",
    "    storage_options={\"anon\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open catalog and produce a content summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the catalog description file location\n",
    "\n",
    "# Open the catalog\n",
    "col = intake.open_esm_datastore(catalog_url)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a catalog content summary.\n",
    "\n",
    "uniques = col.unique()\n",
    "\n",
    "print(f'variables: {uniques[\"variable\"]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data into xarray using the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_var = 'PS'\n",
    "\n",
    "col_subset = col.search(variable=data_var)\n",
    "col_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the chosen Zarr store attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert catalog subset to a dictionary of xarray datasets, and use the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = col_subset.to_dataset_dict(\n",
    "    xarray_open_kwargs={\"consolidated\": True}, storage_options=storage_options\n",
    ")\n",
    "print(f\"\\nDataset dictionary keys:\\n {dsets.keys()}\")\n",
    "\n",
    "# Load the first dataset and display a summary.\n",
    "dataset_key = list(dsets.keys())[0]\n",
    "ds = dsets[dataset_key]\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Plot Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get consistently shaped data slices for both 2D and 3D variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSlice(ds, data_var):\n",
    "    '''If the data has vertical levels, choose the level closest\n",
    "       to the Earth's surface for 2-D diagnostic plots.\n",
    "    '''\n",
    "    data_slice = ds[data_var]\n",
    "\n",
    "    if 'lev' in data_slice.dims:\n",
    "        lastLevel = ds.lev.values[-1]\n",
    "        data_slice = data_slice.sel(lev = lastLevel)\n",
    "        data_slice = data_slice.squeeze()\n",
    "\n",
    "    return data_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get lat/lon dimension names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpatialDimensionNames(data_slice):\n",
    "    '''Get the spatial dimension names for this data slice.\n",
    "    '''\n",
    "    # Determine lat/lon conventions for this slice.\n",
    "    lat_dim = 'lat' if 'lat' in data_slice.dims else 'slat'\n",
    "    lon_dim = 'lon' if 'lon' in data_slice.dims else 'slon'\n",
    "    \n",
    "    return [lat_dim, lon_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce Time Series Spaghetti Plot of Ensemble Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_timeseries(ds, data_var, store_name):\n",
    "    '''Create a spaghetti plot for a given variable.\n",
    "    '''\n",
    "    figWidth = 25 \n",
    "    figHeight = 20\n",
    "    linewidth = 0.5\n",
    "\n",
    "    numPlotsPerPage = 3\n",
    "    numPlotCols = 1\n",
    "    \n",
    "    # Plot the aggregate statistics across time.\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(figWidth, figHeight))\n",
    "\n",
    "    data_slice = getSlice(ds, data_var)\n",
    "    spatial_dims = getSpatialDimensionNames(data_slice)\n",
    "\n",
    "    unit_string = ds[data_var].attrs['units']\n",
    "\n",
    "    # Persist the slice so it's read from disk only once.\n",
    "    # This is faster when data values are reused many times.\n",
    "    data_slice = data_slice.persist()\n",
    "\n",
    "    max_vals = data_slice.max(dim = spatial_dims).transpose()\n",
    "    mean_vals = data_slice.mean(dim = spatial_dims).transpose()\n",
    "    min_vals = data_slice.min(dim = spatial_dims).transpose()\n",
    "\n",
    "    \n",
    "    rangeMaxs = max_vals.max(dim = 'member_id')\n",
    "    rangeMins = max_vals.min(dim = 'member_id')\n",
    "    axs[0].set_facecolor('lightgrey')\n",
    "    axs[0].fill_between(ds.time, rangeMins, rangeMaxs, linewidth=linewidth, color='white')\n",
    "    axs[0].plot(ds.time, max_vals, linewidth=linewidth, color='red', alpha=0.1)\n",
    "    axs[0].set_title('Ensemble Member Maxima Over Time', fontsize=20)\n",
    "    axs[0].set_ylabel(unit_string)\n",
    "\n",
    "    rangeMaxs = mean_vals.max(dim = 'member_id')\n",
    "    rangeMins = mean_vals.min(dim = 'member_id')\n",
    "    axs[1].set_facecolor('lightgrey')\n",
    "    axs[1].fill_between(ds.time, rangeMins, rangeMaxs, linewidth=linewidth, color='white')\n",
    "    axs[1].plot(ds.time, mean_vals, linewidth=linewidth, color='red', alpha=0.1)\n",
    "    axs[1].set_title('Ensemble Member Means Over Time', fontsize=20)\n",
    "    axs[1].set_ylabel(unit_string)\n",
    "\n",
    "    rangeMaxs = min_vals.max(dim = 'member_id')\n",
    "    rangeMins = min_vals.min(dim = 'member_id')\n",
    "    axs[2].set_facecolor('lightgrey')\n",
    "    axs[2].fill_between(ds.time, rangeMins, rangeMaxs, linewidth=linewidth, color='white')\n",
    "    axs[2].plot(ds.time, min_vals, linewidth=linewidth, color='red', alpha=0.1)\n",
    "    axs[2].set_title('Ensemble Member Minima Over Time', fontsize=20)\n",
    "    axs[2].set_ylabel(unit_string)\n",
    "\n",
    "    plt.suptitle(store_name, fontsize=25)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually Create Spaghetti Plot Showing All Ensemble Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "store_name = f'{data_var}.zarr'\n",
    "fig = plot_timeseries(ds, data_var, store_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Download the figure\n",
    "\n",
    "To download the figure plot file:\n",
    "* Run the following command.\n",
    "* Find the file using the Jupyter file browser in the left sidebar.\n",
    "* Right-click the file name, and select \"Download\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f'{data_var}.zarr.pdf', facecolor='white', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release the Dask workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-ncar-dart-cam6]",
   "language": "python",
   "name": "conda-env-miniconda3-ncar-dart-cam6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
